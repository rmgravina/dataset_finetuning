{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pprint import pprint\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Carregar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './dataset/input/'\n",
    "\n",
    "size = 0\n",
    "for file in os.listdir('./dataset/input'):\n",
    "    with open(file_path+file, encoding='utf-8') as f:\n",
    "        conteudo = f.read()\n",
    "        conteudo = conteudo.replace('\\n', '').replace('\\r', '').replace('\\t', '').replace('__________________________', '')\n",
    "        conteudo = conteudo.split(' ')\n",
    "        print(file)\n",
    "        print(\"A quantidade de palavras do arquivo é: \", len(conteudo))\n",
    "        size += len(conteudo)\n",
    "    \n",
    "    print(\"A quantidade total de palavras (atualizada) é: \", size)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245074"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O custo total de processamento é: \n",
      "\n",
      "-> gpt-3.5-turbo: R$ 2.45\n"
     ]
    }
   ],
   "source": [
    "print(\"O custo total de processamento é: \\n\")\n",
    "\n",
    "dolar = 5\n",
    "k_reais = 0.0015 * dolar\n",
    "token_palavras = 750\n",
    "custo_total = ((size / token_palavras) * (k_reais))\n",
    "\n",
    "print(\"-> gpt-3.5-turbo: R$\", round(custo_total, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len,\n",
    "    separators=['.', '?', '!']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [00:00<00:00, 3446.45it/s]\n"
     ]
    }
   ],
   "source": [
    "file_path = './dataset/input/'\n",
    "\n",
    "dict = {'file_name': [], 'chunk': []}\n",
    "\n",
    "for file in tqdm(os.listdir('./dataset/input')):\n",
    "    with open(file_path+file, encoding='utf-8') as f:\n",
    "        conteudo = f.read()\n",
    "        conteudo = conteudo.replace('\\n', '').replace('\\r', '').replace('\\t', '').replace('__________________________', '')\n",
    "        chunks = text_splitter.create_documents([conteudo])\n",
    "        for chunk in chunks:\n",
    "            if chunk.page_content[:1] == '.':\n",
    "                # remove o primeiro ponto\n",
    "                chunk.page_content = chunk.page_content[1:]\n",
    "#                print(chunk.page_content)\n",
    "            dict['file_name'].append(file)\n",
    "            dict['chunk'].append(chunk.page_content)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df['file_name'].unique():\n",
    "    print(i)\n",
    "    for j in df[df['file_name'] == i]['chunk']:\n",
    "        print(j)\n",
    "    print(\"\\n\\n\")\n",
    "    time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./dataset/output/dataset.csv', index=False, sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataset_ft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
